{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Singular Value Decomposition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vdDYXzj3axLO",
        "N-vXld-yBEGO"
      ],
      "mount_file_id": "1K5nY43aRdJdOfYq2FPIeF890Xeq_7TpA",
      "authorship_tag": "ABX9TyNKX/N978AOMiIvJ+imyRC3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomdeepAcharyya/Recommender-Systems/blob/main/Singular_Value_Decomposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Singular Value Decomposition"
      ],
      "metadata": {
        "id": "nUYjXy-fkKnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTZ2nd_2aLKx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import cmake\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn import svm\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.linear_model import orthogonal_mp_gram"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from ksvd import ApproximateKSVD\n",
        "from sklearn.decomposition import DictionaryLearning\n",
        "import sklearn.utils._testing\n",
        "from sklearn.utils._testing import assert_array_almost_equal\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.linalg import norm"
      ],
      "metadata": {
        "id": "d2ZW1k_Va5PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tripadvisor review Dataset\n",
        "path = r'/content/drive/MyDrive/Per_CD_RS/tripadvisor_reviews_with_country.csv'\n",
        "with open(path, encoding=\"utf-8\", errors='ignore') as infile:\n",
        "  tr = pd.read_csv(infile)\n",
        "tr = tr.rename(columns={\"username\":\"userId\", \"taObject\":\"itemId\"})\n",
        "pred_df = tr[['userId', 'itemId','rating', 'open', 'cons','extra','agree', 'neuro']]"
      ],
      "metadata": {
        "id": "HQA6etx9aSBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# amazon review dataset magazines csv\n",
        "path = r'/content/drive/MyDrive/Per_CD_RS/Amazon_Text_Digital_Music.json'\n",
        "with open(path, encoding=\"utf-8\", errors='ignore') as infile:\n",
        "  az = pd.read_json(infile, lines=True, nrows=12000)\n",
        "az = az.rename(columns={\"reviewerID\":\"userId\", \"asin\":\"itemId\", \"overall\":\"rating\"})"
      ],
      "metadata": {
        "id": "beAm2hI-afd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# amazon review dataset movies json\n",
        "path = r'/content/drive/MyDrive/Per_CD_RS/Amazon_fashion_filtered.csv'\n",
        "with open(path, encoding=\"utf-8\", errors='ignore') as infile:\n",
        "  az = pd.read_csv(infile)\n",
        "#am = am.rename(columns={\"reviewerID\":\"userId\", \"asin\":\"itemId\", \"overall\":\"rating\"})"
      ],
      "metadata": {
        "id": "65Cn96ykxvyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tripadvisor review Dataset\n",
        "path = r'/content/drive/MyDrive/Per_CD_RS/pers_fashion_filtered.csv'\n",
        "with open(path, encoding=\"utf-8\", errors='ignore') as infile:\n",
        "  arr = pd.read_csv(infile)\n",
        "arr = arr[['0','1','2','3','4']]\n",
        "arr.columns=['open', 'cons','extra','agree', 'neuro']"
      ],
      "metadata": {
        "id": "QNcUUoNzfMk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tgt = az\n",
        "src = az"
      ],
      "metadata": {
        "id": "A8jaryLxagEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr.shape, az.shape)\n",
        "az = az[0:len(arr)]\n",
        "print(arr.shape, az.shape)"
      ],
      "metadata": {
        "id": "ABKG5Cqrj2vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae400c9d-a550-4c61-a59c-980d201a7d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7841, 5) (7891, 6)\n",
            "(7841, 5) (7841, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_pers = arr[['open', 'cons', 'extra', 'agree', 'neuro']]\n",
        "#tgt_pers[0]\n",
        "pred_df = pd.DataFrame()\n",
        "pred_df = tgt_pers"
      ],
      "metadata": {
        "id": "K1VjWux3flZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df['userId'] = src['userId']\n",
        "pred_df['itemId'] = src['itemId']\n",
        "pred_df['rating'] = src['rating']"
      ],
      "metadata": {
        "id": "7zv6IfyifqIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.open.value_counts()"
      ],
      "metadata": {
        "id": "rqW4I7BXkJQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KSVD"
      ],
      "metadata": {
        "id": "vdDYXzj3axLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ApproximateKSVD(object):\n",
        "    def __init__(self, n_components, max_iter=100, tol=1e-4,\n",
        "                 transform_n_nonzero_coefs=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_components:\n",
        "            Number of dictionary elements\n",
        "        max_iter:\n",
        "            Maximum number of iterations\n",
        "        tol:\n",
        "            tolerance for error\n",
        "        transform_n_nonzero_coefs:\n",
        "            Number of nonzero coefficients to target\n",
        "        \"\"\"\n",
        "        self.components_ = None\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.n_components = n_components\n",
        "        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n",
        "\n",
        "    def _update_dict(self, X, D, gamma):\n",
        "        for j in range(self.n_components):\n",
        "            I = gamma[:, j] > 0\n",
        "            if np.sum(I) == 0:\n",
        "                continue\n",
        "\n",
        "            D[j, :] = 0\n",
        "            g = gamma[I, j].T\n",
        "            r = X[I, :] - gamma[I, :].dot(D)\n",
        "            d = r.T.dot(g)\n",
        "            d /= np.linalg.norm(d)\n",
        "            g = r.dot(d)\n",
        "            D[j, :] = d\n",
        "            gamma[I, j] = g.T\n",
        "        return D, gamma\n",
        "\n",
        "    def _initialize(self, X):\n",
        "        if min(X.shape) < self.n_components:\n",
        "            D = np.random.randn(self.n_components, X.shape[1])\n",
        "        else:\n",
        "            u, s, vt = sp.sparse.linalg.svds(X, k=self.n_components)\n",
        "            D = np.dot(np.diag(s), vt)\n",
        "        D /= np.linalg.norm(D, axis=1)[:, np.newaxis]\n",
        "        return D\n",
        "\n",
        "    def _transform(self, D, X):\n",
        "        gram = D.dot(D.T)\n",
        "        Xy = D.dot(X.T)\n",
        "\n",
        "        n_nonzero_coefs = self.transform_n_nonzero_coefs\n",
        "        if n_nonzero_coefs is None:\n",
        "            n_nonzero_coefs = int(0.1 * X.shape[1])\n",
        "\n",
        "        return orthogonal_mp_gram(\n",
        "            gram, Xy, n_nonzero_coefs=n_nonzero_coefs).T\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: shape = [n_samples, n_features]\n",
        "        \"\"\"\n",
        "        D = self._initialize(X)\n",
        "        for i in range(self.max_iter):\n",
        "            gamma = self._transform(D, X)\n",
        "            e = np.linalg.norm(X - gamma.dot(D))\n",
        "            if e < self.tol:\n",
        "                break\n",
        "            D, gamma = self._update_dict(X, D, gamma)\n",
        "\n",
        "        self.components_ = D\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self._transform(self.components_, X)\n"
      ],
      "metadata": {
        "id": "hB-6lDWVaiXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_initialize_with_small_n_features(X, k, Y):\n",
        "    N = X.shape[0]\n",
        "    n_components = k \n",
        "    n_features = X.shape[1]\n",
        "    #X = np.random.randn(N, n_features)\n",
        "    dico = ApproximateKSVD(n_components=n_components, transform_n_nonzero_coefs=n_components)\n",
        "    dico.fit(X)\n",
        "    dictionary = dico.fit(X).components_\n",
        "    gamma = dico.transform(X)\n",
        "    pred_d = dico.fit(Y).components_\n",
        "    pred_g = dico.transform(Y)\n",
        "    pred = pred_g @ pred_d\n",
        "    return dictionary, gamma, pred"
      ],
      "metadata": {
        "id": "cm6vM_Nsa1xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_fit():\n",
        "    np.random.seed(0)\n",
        "    N = 1000\n",
        "    L = 64\n",
        "    n_features = 128\n",
        "    B = np.array(sp.sparse.random(N, L, density=0.5).todense())\n",
        "    D = np.random.randn(L, n_features)\n",
        "    X = np.dot(B, D)\n",
        "    dico = ApproximateKSVD(n_components=L, transform_n_nonzero_coefs=L)\n",
        "    dico.fit(X)\n",
        "    gamma = dico.transform(X)\n",
        "    assert_array_almost_equal(X, gamma.dot(dico.components_))"
      ],
      "metadata": {
        "id": "7BKSXPNabjWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_size():\n",
        "    np.random.seed(0)\n",
        "    N = 50\n",
        "    L = 12\n",
        "    n_features = 16\n",
        "    D = np.random.randn(L, n_features)\n",
        "    B = np.array(sp.sparse.random(N, L, density=0.5).todense())\n",
        "    X = np.dot(B, D)\n",
        "    dico1 = ApproximateKSVD(n_components=L, transform_n_nonzero_coefs=L)\n",
        "    dico1.fit(X)\n",
        "    gamma1 = dico1.transform(X)\n",
        "    e1 = norm(X - gamma1.dot(dico1.components_))\n",
        "\n",
        "    dico2 = DictionaryLearning(n_components=L, transform_n_nonzero_coefs=L)\n",
        "    dico2.fit(X)\n",
        "    gamma2 = dico2.transform(X)\n",
        "    e2 = norm(X - gamma2.dot(dico2.components_))\n",
        "\n",
        "    assert dico1.components_.shape == dico2.components_.shape\n",
        "    assert gamma1.shape == gamma2.shape\n",
        "    assert e1 < e2"
      ],
      "metadata": {
        "id": "QKsTq69GbuVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rating matrix wrt user u\n",
        "ru = src.pivot_table(index='userId',columns='itemId',values='rating')\n",
        "ru = ru.fillna(0)\n",
        "ru_m = ru > 0\n",
        "ru_m = ru_m.replace(True, 1)\n",
        "ru_m = ru_m.replace(False, 0)\n",
        "ru = np.array(ru)\n",
        "ru_m = np.array(ru_m)"
      ],
      "metadata": {
        "id": "AfN2C3SAbzCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.9\n",
        "df_copy = src.copy()\n",
        "train_set = df_copy.sample(frac=train_size).reset_index()\n",
        "user_features_train = np.array(train_set[['open', 'cons', 'extra', 'agree', 'neuro']].fillna(0))\n",
        "test_set = df_copy.drop(train_set.index).reset_index()\n",
        "user_features_test = np.array(test_set[['open', 'cons', 'extra', 'agree', 'neuro']].fillna(0))\n",
        "user_features_unique = np.array(src.groupby(by='userId').mean()[['open', 'cons', 'extra', 'agree', 'neuro']].fillna(0))\n",
        "n_dims = 10\n",
        "n_features = 10\n",
        "parameters = {}"
      ],
      "metadata": {
        "id": "r78blBz0p4Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    user_to_row = {}\n",
        "    item_to_column = {}\n",
        "    uniq_users = np.unique(train_set.userId)\n",
        "    uniq_items = np.unique(train_set.itemId)\n",
        "\n",
        "    for i, user_id in enumerate(uniq_users):\n",
        "        user_to_row[user_id] = i\n",
        "\n",
        "    for j, item_id in enumerate(uniq_items):\n",
        "        item_to_column[item_id] = j\n",
        "\n",
        "    n_users = len(uniq_users)\n",
        "    n_items = len(uniq_items)\n",
        "    rating =[]\n",
        "    for i in range(n_users):\n",
        "      rating.append(np.average([i]))\n",
        "\n",
        "    R = np.zeros((n_users, n_items))\n",
        "    for index, row in train_set.iterrows():\n",
        "        i = user_to_row[row.userId]\n",
        "        j = item_to_column[row.itemId]\n",
        "        R[i, j] = row.rating"
      ],
      "metadata": {
        "id": "7zBTXLZvqHwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    user_to_row = {}\n",
        "    item_to_column = {}\n",
        "    uniq_users = np.unique(test_set.userId)\n",
        "    uniq_items = np.unique(test_set.itemId)\n",
        "\n",
        "    for i, user_id in enumerate(uniq_users):\n",
        "        user_to_row[user_id] = i\n",
        "\n",
        "    for j, item_id in enumerate(uniq_items):\n",
        "        item_to_column[item_id] = j\n",
        "\n",
        "    n_users = len(uniq_users)\n",
        "    n_items = len(uniq_items)\n",
        "    rating =[]\n",
        "    for i in range(n_users):\n",
        "      rating.append(np.average([i]))\n",
        "\n",
        "    Rt = np.zeros((n_users, n_items))\n",
        "    for index, row in test_set.iterrows():\n",
        "        i = user_to_row[row.userId]\n",
        "        j = item_to_column[row.itemId]\n",
        "        Rt[i, j] = row.rating"
      ],
      "metadata": {
        "id": "T0Lqk--owAhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d, g, p = test_initialize_with_small_n_features(R, 10, Rt)"
      ],
      "metadata": {
        "id": "Ed8aJ8m4if-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = g@d"
      ],
      "metadata": {
        "id": "Vhe-rZ2Zj7Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARuc6RREyxG5",
        "outputId": "ed364aa7-6db6-4a36-a70c-45ec3a419736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.46532366e-06, -4.28261641e-18,  1.95843342e-04, ...,\n",
              "         1.09138150e-19, -1.03862772e-05, -6.91243322e-17],\n",
              "       [-6.56135567e-09, -4.33398786e-18, -2.13588181e-07, ...,\n",
              "         1.10447299e-19,  7.11075204e-04, -6.99535023e-17],\n",
              "       [ 1.14987969e-07,  9.72937553e-20,  3.64012027e-06, ...,\n",
              "        -2.47943300e-21,  2.41260042e-07,  1.57038717e-18],\n",
              "       ...,\n",
              "       [-6.11345124e-12, -5.43425251e-20, -1.85610347e-10, ...,\n",
              "         1.38486432e-21,  1.58246035e-05, -8.77125196e-19],\n",
              "       [-6.20530675e-11,  3.92845451e-22, -1.98667064e-09, ...,\n",
              "        -1.00112692e-23,  8.04738036e-09,  6.34079191e-21],\n",
              "       [ 5.51852909e-09, -4.03021557e-18,  1.57454620e-07, ...,\n",
              "         1.02705970e-19, -8.59118240e-06, -6.50504115e-17]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(pred)\n",
        "p_n = pred > 2.5\n",
        "p_n = p_n.replace(True, 1)\n",
        "p_n = p_n.replace(False, 0)\n",
        "p_n = np.array(p_n)"
      ],
      "metadata": {
        "id": "F6-vDP6Mrytx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mae = mean_absolute_error(Rt, p)\n",
        "rmse = np.sqrt(mean_squared_error(Rt, p))\n",
        "print(mae, rmse)\n",
        "# 0.004541958435804962\n",
        "# 0.0010510987831314456"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5DAbGJcrXOP",
        "outputId": "1cd87235-baea-4dad-baf1-15feb9794146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03246389874443447 0.3519122274304687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD++"
      ],
      "metadata": {
        "id": "2mSan7fBl0er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from functools import wraps\n",
        "from math import trunc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numba import njit\n",
        "#from .__version__ import __version__\n",
        "__version__ = '0.0.1.dev1'\n",
        "__all__ = ['get_version', '_timer','SVD','_compute_val_metrics', '_initialization','_run_epoch','_shuffle']"
      ],
      "metadata": {
        "id": "65vle24dl2lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_version():\n",
        "    return __version__\n",
        "\n",
        "    \n",
        "def _timer(text=''):\n",
        "    \"\"\"Decorator, prints execution time of the decorated function.\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        Text to print before time display.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> @_timer(text='Greetings took ')\n",
        "    ... def say_hi():\n",
        "    ...    time.sleep(1)\n",
        "    ...    print(\"Hey! What's up!\")\n",
        "    ...\n",
        "    >>> say_hi()\n",
        "    Hey! What's up!\n",
        "    Greetings took 1 sec\n",
        "    \"\"\"\n",
        "    def decorator(func):\n",
        "\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start = time.time()\n",
        "            result = func(*args, **kwargs)\n",
        "            end = time.time()\n",
        "\n",
        "            hours = trunc((end - start) / 3600)\n",
        "            minutes = trunc((end - start) / 60)\n",
        "            seconds = round((end - start) % 60)\n",
        "\n",
        "            if hours > 1:\n",
        "                print(text + '{} hours {} min and {} sec'.format(hours,\n",
        "                                                                 minutes,\n",
        "                                                                 seconds))\n",
        "            elif hours == 1:\n",
        "                print(text + '{} hour {} min and {} sec'.format(hours, minutes,\n",
        "                                                                seconds))\n",
        "            elif minutes >= 1:\n",
        "                print(text + '{} min and {} sec'.format(minutes, seconds))\n",
        "            else:\n",
        "                print(text + '{} sec'.format(seconds))\n",
        "\n",
        "            return result\n",
        "\n",
        "        return wrapper\n",
        "\n",
        "    return decorator"
      ],
      "metadata": {
        "id": "gReXhsOVmdak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def _shuffle(X):\n",
        "    np.random.shuffle(X)\n",
        "    return X\n",
        "\n",
        "\n",
        "@njit\n",
        "def _initialization(n_users, n_items, n_factors):\n",
        "    \"\"\"Initializes biases and latent factor matrices.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_users : int\n",
        "        Number of unique users.\n",
        "    n_items : int\n",
        "        Number of unique items.\n",
        "    n_factors : int\n",
        "        Number of factors.\n",
        "    Returns\n",
        "    -------\n",
        "    bu : numpy.array\n",
        "        User biases vector.\n",
        "    bi : numpy.array\n",
        "        Item biases vector.\n",
        "    pu : numpy.array\n",
        "        User latent factors matrix.\n",
        "    qi : numpy.array\n",
        "        Item latent factors matrix.\n",
        "    \"\"\"\n",
        "    bu = np.zeros(n_users)\n",
        "    bi = np.zeros(n_items)\n",
        "\n",
        "    pu = np.random.normal(0, .1, (n_users, n_factors))\n",
        "    qi = np.random.normal(0, .1, (n_items, n_factors))\n",
        "\n",
        "    return bu, bi, pu, qi\n",
        "\n",
        "\n",
        "@njit\n",
        "def _run_epoch(X, bu, bi, pu, qi, global_mean, n_factors, lr, reg):\n",
        "    \"\"\"Runs an epoch, updating model weights (pu, qi, bu, bi).\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : numpy.array\n",
        "        Training set.\n",
        "    bu : numpy.array\n",
        "        User biases vector.\n",
        "    bi : numpy.array\n",
        "        Item biases vector.\n",
        "    pu : numpy.array\n",
        "        User latent factors matrix.\n",
        "    qi : numpy.array\n",
        "        Item latent factors matrix.\n",
        "    global_mean : float\n",
        "        Ratings arithmetic mean.\n",
        "    n_factors : int\n",
        "        Number of latent factors.\n",
        "    lr : float\n",
        "        Learning rate.\n",
        "    reg : float\n",
        "        L2 regularization factor.\n",
        "    Returns:\n",
        "    --------\n",
        "    bu : numpy.array\n",
        "        User biases vector.\n",
        "    bi : numpy.array\n",
        "        Item biases vector.\n",
        "    pu : numpy.array\n",
        "        User latent factors matrix.\n",
        "    qi : numpy.array\n",
        "        Item latent factors matrix.\n",
        "    \"\"\"\n",
        "    for i in range(X.shape[0]):\n",
        "        user, item, rating = int(X[i, 0]), int(X[i, 1]), X[i, 2]\n",
        "\n",
        "        # Predict current rating\n",
        "        pred = global_mean + bu[user] + bi[item]\n",
        "\n",
        "        for factor in range(n_factors):\n",
        "            pred += pu[user, factor] * qi[item, factor]\n",
        "\n",
        "        err = rating - pred\n",
        "\n",
        "        # Update biases\n",
        "        bu[user] += lr * (err - reg * bu[user])\n",
        "        bi[item] += lr * (err - reg * bi[item])\n",
        "\n",
        "        # Update latent factors\n",
        "        for factor in range(n_factors):\n",
        "            puf = pu[user, factor]\n",
        "            qif = qi[item, factor]\n",
        "\n",
        "            pu[user, factor] += lr * (err * qif - reg * puf)\n",
        "            qi[item, factor] += lr * (err * puf - reg * qif)\n",
        "\n",
        "    return bu, bi, pu, qi\n",
        "\n",
        "\n",
        "@njit\n",
        "def _compute_val_metrics(X_val, bu, bi, pu, qi, global_mean, n_factors):\n",
        "    \"\"\"Computes validation metrics (loss, rmse, and mae).\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_val : numpy.array\n",
        "        Validation set.\n",
        "    bu : numpy.array\n",
        "        User biases vector.\n",
        "    bi : numpy.array\n",
        "        Item biases vector.\n",
        "    pu : numpy.array\n",
        "        User latent factors matrix.\n",
        "    qi : numpy.array\n",
        "        Item latent factors matrix.\n",
        "    global_mean : float\n",
        "        Ratings arithmetic mean.\n",
        "    n_factors : int\n",
        "        Number of latent factors.\n",
        "    Returns\n",
        "    -------\n",
        "    loss, rmse, mae : tuple of floats\n",
        "        Validation loss, rmse and mae.\n",
        "    \"\"\"\n",
        "    residuals = []\n",
        "\n",
        "    for i in range(X_val.shape[0]):\n",
        "        user, item, rating = int(X_val[i, 0]), int(X_val[i, 1]), X_val[i, 2]\n",
        "        pred = global_mean\n",
        "\n",
        "        if user > -1:\n",
        "            pred += bu[user]\n",
        "\n",
        "        if item > -1:\n",
        "            pred += bi[item]\n",
        "\n",
        "        if (user > -1) and (item > -1):\n",
        "            for factor in range(n_factors):\n",
        "                pred += pu[user, factor] * qi[item, factor]\n",
        "\n",
        "        residuals.append(rating - pred)\n",
        "\n",
        "    residuals = np.array(residuals)\n",
        "    loss = np.square(residuals).mean()\n",
        "    rmse = np.sqrt(loss)\n",
        "    mae = np.absolute(residuals).mean()\n",
        "    print(\"rmse\", rmse, \"mae\", mae)\n",
        "\n",
        "    return loss, rmse, mae"
      ],
      "metadata": {
        "id": "BvOUycAEoQh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVD:\n",
        "    \"\"\"Implements Simon Funk famous SVD algorithm.\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : float, default=.005\n",
        "        Learning rate.\n",
        "    reg : float, default=.02\n",
        "        L2 regularization factor.\n",
        "    n_epochs : int, default=20\n",
        "        Number of SGD iterations.\n",
        "    n_factors : int, default=100\n",
        "        Number of latent factors.\n",
        "    early_stopping : bool, default=False\n",
        "        Whether or not to stop training based on a validation monitoring.\n",
        "    shuffle : bool, default=False\n",
        "        Whether or not to shuffle the training set before each epoch.\n",
        "    min_delta : float, default=.001\n",
        "        Minimun delta to argue for an improvement.\n",
        "    min_rating : int, default=1\n",
        "        Minimum value a rating should be clipped to at inference time.\n",
        "    max_rating : int, default=5\n",
        "        Maximum value a rating should be clipped to at inference time.\n",
        "    Attributes\n",
        "    ----------\n",
        "    user_mapping_ : dict\n",
        "        Maps user ids to their indexes.\n",
        "    item_mapping_ : dict\n",
        "        Maps item ids to their indexes.\n",
        "    global_mean_ : float\n",
        "        Ratings arithmetic mean.\n",
        "    pu_ : numpy.array\n",
        "        User latent factors matrix.\n",
        "    qi_ : numpy.array\n",
        "        Item latent factors matrix.\n",
        "    bu_ : numpy.array\n",
        "        User biases vector.\n",
        "    bi_ : numpy.array\n",
        "        Item biases vector.\n",
        "    metrics_ : pandas.DataFrame\n",
        "        Validation metrics at each epoch. Column names are 'Loss', 'RMSE', and\n",
        "        'MAE'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lr=.001, reg=.01, n_epochs=100, n_factors=40,\n",
        "                 early_stopping=False, shuffle=False, min_delta=.001,\n",
        "                 min_rating=1, max_rating=5):\n",
        "\n",
        "        self.lr = lr\n",
        "        self.reg = reg\n",
        "        self.n_epochs = n_epochs\n",
        "        self.n_factors = n_factors\n",
        "        self.early_stopping = early_stopping\n",
        "        self.shuffle = shuffle\n",
        "        self.min_delta = min_delta\n",
        "        self.min_rating = min_rating\n",
        "        self.max_rating = max_rating\n",
        "\n",
        "    @_timer(text='\\nTraining took ')\n",
        "    def fit(self, X, X_val=None):\n",
        "        \"\"\"Learns model weights from input data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas.DataFrame\n",
        "            Training set, must have 'u_id' for user ids, 'i_id' for item ids,\n",
        "            and 'rating' column names.\n",
        "        X_val : pandas.DataFrame, default=None\n",
        "            Validation set with the same column structure as X.\n",
        "        Returns\n",
        "        -------\n",
        "        self : SVD object\n",
        "            The current fitted object.\n",
        "        \"\"\"\n",
        "        X = self._preprocess_data(X)\n",
        "\n",
        "        if X_val is not None:\n",
        "            X_val = self._preprocess_data(X_val, train=False, verbose=False)\n",
        "            self._init_metrics()\n",
        "\n",
        "        self.global_mean_ = np.mean(X[:, 2])\n",
        "        self._run_sgd(X, X_val)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _preprocess_data(self, X, train=True, verbose=True):\n",
        "        \"\"\"Maps user and item ids to their indexes.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas.DataFrame\n",
        "            Dataset, must have 'u_id' for user ids, 'i_id' for item ids, and\n",
        "            'rating' column names.\n",
        "        train : boolean\n",
        "            Whether or not X is the training set or the validation set.\n",
        "        Returns\n",
        "        -------\n",
        "        X : numpy.array\n",
        "            Mapped dataset.\n",
        "        \"\"\"\n",
        "        print('Preprocessing data...\\n')\n",
        "        X = X.copy()\n",
        "\n",
        "        if train:  # Mappings have to be created\n",
        "            user_ids = X['u_id'].unique().tolist()\n",
        "            item_ids = X['i_id'].unique().tolist()\n",
        "\n",
        "            n_users = len(user_ids)\n",
        "            n_items = len(item_ids)\n",
        "\n",
        "            user_idx = range(n_users)\n",
        "            item_idx = range(n_items)\n",
        "\n",
        "            self.user_mapping_ = dict(zip(user_ids, user_idx))\n",
        "            self.item_mapping_ = dict(zip(item_ids, item_idx))\n",
        "\n",
        "        X['u_id'] = X['u_id'].map(self.user_mapping_)\n",
        "        X['i_id'] = X['i_id'].map(self.item_mapping_)\n",
        "\n",
        "        # Tag validation set unknown users/items with -1 (enables\n",
        "        # `fast_methods._compute_val_metrics` detecting them)\n",
        "        X.fillna(-1, inplace=True)\n",
        "\n",
        "        X['u_id'] = X['u_id'].astype(np.int32)\n",
        "        X['i_id'] = X['i_id'].astype(np.int32)\n",
        "\n",
        "        return X[['u_id', 'i_id', 'rating']].values\n",
        "\n",
        "    def _init_metrics(self):\n",
        "        metrics = np.zeros((self.n_epochs, 3), dtype=float)\n",
        "        self.metrics_ = pd.DataFrame(metrics, columns=['Loss', 'RMSE', 'MAE'])\n",
        "\n",
        "    def _run_sgd(self, X, X_val):\n",
        "        \"\"\"Runs SGD algorithm, learning model weights.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : numpy.array\n",
        "            Training set, first column must be user indexes, second one item\n",
        "            indexes, and third one ratings.\n",
        "        X_val : numpy.array or None\n",
        "            Validation set with the same structure as X.\n",
        "        \"\"\"\n",
        "        n_users = len(np.unique(X[:, 0]))\n",
        "        n_items = len(np.unique(X[:, 1]))\n",
        "\n",
        "        bu, bi, pu, qi = _initialization(n_users, n_items, self.n_factors)\n",
        "\n",
        "        # Run SGD\n",
        "        for epoch_ix in range(self.n_epochs):\n",
        "            start = self._on_epoch_begin(epoch_ix)\n",
        "\n",
        "            if self.shuffle:\n",
        "                X = _shuffle(X)\n",
        "\n",
        "            bu, bi, pu, qi = _run_epoch(X, bu, bi, pu, qi, self.global_mean_,\n",
        "                                        self.n_factors, self.lr, self.reg)\n",
        "\n",
        "            if X_val is not None:\n",
        "                self.metrics_.loc[epoch_ix, :] = _compute_val_metrics(\n",
        "                                                     X_val, bu, bi, pu, qi,\n",
        "                                                     self.global_mean_,\n",
        "                                                     self.n_factors\n",
        "                                                 )\n",
        "                self._on_epoch_end(start,\n",
        "                                   self.metrics_.loc[epoch_ix, 'Loss'],\n",
        "                                   self.metrics_.loc[epoch_ix, 'RMSE'],\n",
        "                                   self.metrics_.loc[epoch_ix, 'MAE'])\n",
        "\n",
        "                if self.early_stopping:\n",
        "                    val_rmse = self.metrics_['RMSE'].tolist()\n",
        "                    if self._early_stopping(val_rmse, epoch_ix,\n",
        "                                            self.min_delta):\n",
        "                        break\n",
        "\n",
        "            else:\n",
        "                self._on_epoch_end(start)\n",
        "\n",
        "        self.bu_ = bu\n",
        "        self.bi_ = bi\n",
        "        self.pu_ = pu\n",
        "        self.qi_ = qi\n",
        "        #print(self.metrics_['RMSE'], self.metrics_['MAE'])\n",
        "\n",
        "    def predict(self, X, clip=True):\n",
        "        \"\"\"Returns estimated ratings of several given user/item pairs.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas.DataFrame\n",
        "            Storing all user/item pairs we want to predict the ratings. Must\n",
        "            contains columns labeled 'u_id' and 'i_id'.\n",
        "        clip : bool, default=True\n",
        "            Whether to clip the predictions or not.\n",
        "        Returns\n",
        "        -------\n",
        "        predictions : list\n",
        "            Predictions belonging to the input user/item pairs.\n",
        "        \"\"\"\n",
        "        return [\n",
        "            self.predict_pair(u_id, i_id, clip)\n",
        "            for u_id, i_id in zip(X['u_id'], X['i_id'])\n",
        "        ]\n",
        "\n",
        "    def predict_pair(self, u_id, i_id, clip=True):\n",
        "        \"\"\"Returns the model rating prediction for a given user/item pair.\n",
        "        Parameters\n",
        "        ----------\n",
        "        u_id : int\n",
        "            A user id.\n",
        "        i_id : int\n",
        "            An item id.\n",
        "        clip : bool, default=True\n",
        "            Whether to clip the prediction or not.\n",
        "        Returns\n",
        "        -------\n",
        "        pred : float\n",
        "            The estimated rating for the given user/item pair.\n",
        "        \"\"\"\n",
        "        user_known, item_known = False, False\n",
        "        pred = self.global_mean_\n",
        "\n",
        "        if u_id in self.user_mapping_:\n",
        "            user_known = True\n",
        "            u_ix = self.user_mapping_[u_id]\n",
        "            pred += self.bu_[u_ix]\n",
        "\n",
        "        if i_id in self.item_mapping_:\n",
        "            item_known = True\n",
        "            i_ix = self.item_mapping_[i_id]\n",
        "            pred += self.bi_[i_ix]\n",
        "\n",
        "        if user_known and item_known:\n",
        "            pred += np.dot(self.pu_[u_ix], self.qi_[i_ix])\n",
        "\n",
        "        if clip:\n",
        "            pred = self.max_rating if pred > self.max_rating else pred\n",
        "            pred = self.min_rating if pred < self.min_rating else pred\n",
        "\n",
        "        return pred\n",
        "\n",
        "    def _early_stopping(self, val_rmse, epoch_idx, min_delta):\n",
        "        \"\"\"Returns True if validation rmse is not improving.\n",
        "        Last rmse (plus `min_delta`) is compared with the second to last.\n",
        "        Parameters\n",
        "        ----------\n",
        "        val_rmse : list\n",
        "            Validation RMSEs.\n",
        "        min_delta : float\n",
        "            Minimun delta to argue for an improvement.\n",
        "        Returns\n",
        "        -------\n",
        "        early_stopping : bool\n",
        "            Whether to stop training or not.\n",
        "        \"\"\"\n",
        "        if epoch_idx > 0:\n",
        "            if val_rmse[epoch_idx] + min_delta > val_rmse[epoch_idx-1]:\n",
        "                self.metrics_ = self.metrics_.loc[:(epoch_idx+1), :]\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _on_epoch_begin(self, epoch_ix):\n",
        "        \"\"\"Displays epoch starting log and returns its starting time.\n",
        "        Parameters\n",
        "        ----------\n",
        "        epoch_ix : int\n",
        "            Epoch index.\n",
        "        Returns\n",
        "        -------\n",
        "        start : float\n",
        "            Starting time of the current epoch.\n",
        "        \"\"\"\n",
        "        start = time.time()\n",
        "        end = '  | ' if epoch_ix < 9 else ' | '\n",
        "        #print('Epoch {}/{}'.format(epoch_ix + 1, self.n_epochs), end=end)\n",
        "\n",
        "        return start\n",
        "\n",
        "    def _on_epoch_end(self, start, val_loss=None, val_rmse=None, val_mae=None):\n",
        "        \"\"\"Displays epoch ending log.\n",
        "        If self.verbose, computes and displays validation metrics (loss, rmse,\n",
        "        and mae).\n",
        "        Parameters\n",
        "        ----------\n",
        "        start : float\n",
        "            Starting time of the current epoch.\n",
        "        val_loss : float, default=None\n",
        "            Validation loss.\n",
        "        val_rmse : float, default=None\n",
        "            Validation rmse.\n",
        "        val_mae : float, default=None\n",
        "            Validation mae.\n",
        "        \"\"\"\n",
        "        end = time.time()\n",
        "\n",
        "        if val_loss is not None:\n",
        "          pass;\n",
        "            #print(f'val_loss: {val_loss:.2f}', end=' - ')\n",
        "            #print(f'val_rmse: {val_rmse:.2f}', end=' - ')\n",
        "            #print(f'val_mae: {val_mae:.2f}', end=' - ')\n",
        "\n",
        "        #print(f'took {end - start:.1f} sec')\n"
      ],
      "metadata": {
        "id": "3Pqn_4_Wmlbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rating matrix wrt user u\n",
        "ru = pred_df.pivot_table(index='userId',columns='itemId',values='rating')\n",
        "ru = ru.fillna(0)\n",
        "ru_m = ru > 0\n",
        "ru_m = ru_m.replace(True, 1)\n",
        "ru_m = ru_m.replace(False, 0)\n",
        "ru = np.array(ru)\n",
        "ru_m = np.array(ru_m)"
      ],
      "metadata": {
        "id": "XEt3CrgAnNmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.9\n",
        "df_copy = pred_df.copy()\n",
        "train_set = df_copy.sample(frac=train_size).reset_index()\n",
        "user_features_train = np.array(train_set[['open', 'cons', 'extra', 'agree', 'neuro']].fillna(0))\n",
        "test_set = df_copy.drop(train_set.index).reset_index()\n",
        "user_features_test = np.array(test_set[['open', 'cons', 'extra', 'agree', 'neuro']].fillna(0))\n",
        "user_features_unique = np.array(pred_df.groupby(by='userId').mean()[['open', 'cons', 'extra', 'agree', 'neuro']].fillna(0))\n",
        "n_dims = 30\n",
        "n_features = 5\n",
        "parameters = {}"
      ],
      "metadata": {
        "id": "OeoHqi7R4vpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    user_to_row = {}\n",
        "    item_to_column = {}\n",
        "    uniq_users = np.unique(train_set.userId)\n",
        "    uniq_items = np.unique(train_set.itemId)\n",
        "\n",
        "    for i, user_id in enumerate(uniq_users):\n",
        "        user_to_row[user_id] = i\n",
        "\n",
        "    for j, item_id in enumerate(uniq_items):\n",
        "        item_to_column[item_id] = j\n",
        "\n",
        "    n_users = len(uniq_users)\n",
        "    n_items = len(uniq_items)\n",
        "    rating =[]\n",
        "    for i in range(n_users):\n",
        "      rating.append(np.average([i]))\n",
        "\n",
        "    R = np.zeros((n_users, n_items))\n",
        "    for index, row in train_set.iterrows():\n",
        "        i = user_to_row[row.userId]\n",
        "        j = item_to_column[row.itemId]\n",
        "        R[i, j] = row.rating"
      ],
      "metadata": {
        "id": "iHBw5iDn4vpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    user_to_row = {}\n",
        "    item_to_column = {}\n",
        "    uniq_users = np.unique(test_set.userId)\n",
        "    uniq_items = np.unique(test_set.itemId)\n",
        "\n",
        "    for i, user_id in enumerate(uniq_users):\n",
        "        user_to_row[user_id] = i\n",
        "\n",
        "    for j, item_id in enumerate(uniq_items):\n",
        "        item_to_column[item_id] = j\n",
        "\n",
        "    n_users = len(uniq_users)\n",
        "    n_items = len(uniq_items)\n",
        "    rating =[]\n",
        "    for i in range(n_users):\n",
        "      rating.append(np.average([i]))\n",
        "\n",
        "    Rt = np.zeros((n_users, n_items))\n",
        "    for index, row in test_set.iterrows():\n",
        "        i = user_to_row[row.userId]\n",
        "        j = item_to_column[row.itemId]\n",
        "        Rt[i, j] = row.rating"
      ],
      "metadata": {
        "id": "4jHeto4L4vpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = train_set[['userId', 'itemId', 'rating']]\n",
        "df.columns=['u_id', 'i_id', 'rating']"
      ],
      "metadata": {
        "id": "gApsHcNopGiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = test_set[['userId', 'itemId', 'rating']]\n",
        "df_val.columns=['u_id', 'i_id', 'rating']"
      ],
      "metadata": {
        "id": "kCgzYdNzn_fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd = SVD(lr=0.001, reg=0.0001, n_epochs=100, n_factors=10, shuffle=False, min_rating=1, max_rating=5)"
      ],
      "metadata": {
        "id": "77UTh8PArIQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd.fit(X=df, X_val=df_val)"
      ],
      "metadata": {
        "id": "dKSvVhL95a4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac68616-4770-496f-da7b-68276fda8645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "rmse 1.0567729467768796 mae 0.8053163035350284\n",
            "rmse 1.051419451423391 mae 0.8017110358016192\n",
            "rmse 1.0463627358398246 mae 0.7985575981198763\n",
            "rmse 1.041581285761975 mae 0.7957585788322664\n",
            "rmse 1.0370551121343774 mae 0.793217621941852\n",
            "rmse 1.0327656550479243 mae 0.7908646303133726\n",
            "rmse 1.0286956917995937 mae 0.7886540522906789\n",
            "rmse 1.0248292491877546 mae 0.7865712002813467\n",
            "rmse 1.0211515201033232 mae 0.7845920244318076\n",
            "rmse 1.0176487844297917 mae 0.7826840546979221\n",
            "rmse 1.014308334224258 mae 0.7808475010245334\n",
            "rmse 1.0111184031167586 mae 0.7790678858976008\n",
            "rmse 1.0080680998364584 mae 0.7773408132863006\n",
            "rmse 1.005147345749835 mae 0.7756569087973526\n",
            "rmse 1.0023468162775948 mae 0.7740104208221024\n",
            "rmse 0.999657886043124 mae 0.772401406265492\n",
            "rmse 0.9970725775950704 mae 0.7708265188970119\n",
            "rmse 0.99458351354006 mae 0.7692899651601133\n",
            "rmse 0.9921838719175322 mae 0.767789932705952\n",
            "rmse 0.989867344647321 mae 0.7663176700798441\n",
            "rmse 0.9876280988812377 mae 0.7648720123207619\n",
            "rmse 0.9854607410920075 mae 0.7634552543156502\n",
            "rmse 0.9833602837366188 mae 0.7620639249294625\n",
            "rmse 0.981322114335682 mae 0.7606949908727825\n",
            "rmse 0.9793419668158352 mae 0.7593472410501516\n",
            "rmse 0.9774158949682521 mae 0.7580198482835018\n",
            "rmse 0.9755402478827294 mae 0.756712932364715\n",
            "rmse 0.9737116472235054 mae 0.7554242044142214\n",
            "rmse 0.9719269662198156 mae 0.7541524974477984\n",
            "rmse 0.9701833102510574 mae 0.7528967834271538\n",
            "rmse 0.968477998913199 mae 0.7516586983068414\n",
            "rmse 0.966808549459841 mae 0.7504361862989716\n",
            "rmse 0.9651726615178035 mae 0.7492278447051892\n",
            "rmse 0.9635682029835132 mae 0.7480334775992818\n",
            "rmse 0.9619931970124468 mae 0.7468518254786615\n",
            "rmse 0.9604458100198472 mae 0.7456824082369429\n",
            "rmse 0.9589243406163209 mae 0.7445250100194343\n",
            "rmse 0.9574272094074063 mae 0.7433790482732434\n",
            "rmse 0.9559529495909795 mae 0.7422442199249386\n",
            "rmse 0.9545001982912454 mae 0.7411212434477543\n",
            "rmse 0.9530676885723957 mae 0.7400097194780977\n",
            "rmse 0.9516542420792304 mae 0.7389091328055937\n",
            "rmse 0.9502587622558931 mae 0.7378182011564411\n",
            "rmse 0.9488802280975449 mae 0.7367362692534388\n",
            "rmse 0.9475176883932129 mae 0.7356630019530331\n",
            "rmse 0.9461702564211694 mae 0.7345985456419453\n",
            "rmse 0.9448371050612052 mae 0.7335429296753421\n",
            "rmse 0.9435174622908528 mae 0.7324953359212283\n",
            "rmse 0.942210607035212 mae 0.7314554178861248\n",
            "rmse 0.9409158653423171 mae 0.7304227413576302\n",
            "rmse 0.9396326068582822 mae 0.72939696628609\n",
            "rmse 0.9383602415783333 mae 0.728378015769859\n",
            "rmse 0.9370982168518686 mae 0.7273656420782675\n",
            "rmse 0.9358460146213202 mae 0.7263594242934645\n",
            "rmse 0.9346031488761843 mae 0.725359134843104\n",
            "rmse 0.9333691633051507 mae 0.7243645545845052\n",
            "rmse 0.9321436291305031 mae 0.7233754724481335\n",
            "rmse 0.9309261431103513 mae 0.7223940671276583\n",
            "rmse 0.929716325695279 mae 0.721420648447074\n",
            "rmse 0.9285138193271826 mae 0.7204565957063145\n",
            "rmse 0.9273182868689436 mae 0.7194970850231138\n",
            "rmse 0.9261294101546224 mae 0.7185420512658292\n",
            "rmse 0.9249468886505167 mae 0.7175926979668906\n",
            "rmse 0.9237704382183882 mae 0.7166514840898136\n",
            "rmse 0.9225997899726988 mae 0.7157146132206511\n",
            "rmse 0.9214346892244669 mae 0.7147813470163807\n",
            "rmse 0.9202748945048962 mae 0.7138527439589442\n",
            "rmse 0.9191201766624674 mae 0.712927725709689\n",
            "rmse 0.917970318027747 mae 0.7120065741446654\n",
            "rmse 0.9168251116405686 mae 0.7110931610367225\n",
            "rmse 0.9156843605347076 mae 0.7101827155667702\n",
            "rmse 0.9145478770755624 mae 0.7092753931590617\n",
            "rmse 0.913415482346667 mae 0.7083725426008228\n",
            "rmse 0.9122870055813017 mae 0.7074766287746463\n",
            "rmse 0.9111622836356157 mae 0.7065843055011154\n",
            "rmse 0.9100411605001327 mae 0.705696834258795\n",
            "rmse 0.9089234868465899 mae 0.7048116372692975\n",
            "rmse 0.9078091196074733 mae 0.7039284652081231\n",
            "rmse 0.9066979215856594 mae 0.7030471452321164\n",
            "rmse 0.9055897610919357 mae 0.7021681064808137\n",
            "rmse 0.904484511608203 mae 0.7012945894033037\n",
            "rmse 0.9033820514744682 mae 0.7004251581407617\n",
            "rmse 0.9022822635977874 mae 0.6995600934519812\n",
            "rmse 0.9011850351815182 mae 0.6986964878219707\n",
            "rmse 0.9000902574733574 mae 0.6978341205714979\n",
            "rmse 0.898997825530762 mae 0.6969729254544975\n",
            "rmse 0.8979076380024423 mae 0.6961129773588028\n",
            "rmse 0.8968195969247518 mae 0.6952541094032947\n",
            "rmse 0.8957336075318796 mae 0.6943962270085364\n",
            "rmse 0.89464957807882 mae 0.6935392707633135\n",
            "rmse 0.8935674196761751 mae 0.6926840792119235\n",
            "rmse 0.8924870461359704 mae 0.6918299306419792\n",
            "rmse 0.8914083738276513 mae 0.6909766907637778\n",
            "rmse 0.8903313215435306 mae 0.6901241411668931\n",
            "rmse 0.8892558103730517 mae 0.6892722302306565\n",
            "rmse 0.8881817635851952 mae 0.6884209075575918\n",
            "rmse 0.8871091065184656 mae 0.6875701239235236\n",
            "rmse 0.8860377664779708 mae 0.6867198312298225\n",
            "rmse 0.8849676726390265 mae 0.6858699824577912\n",
            "rmse 0.8838987559569063 mae 0.6850221494918397\n",
            "\n",
            "Training took 1 sec\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SVD at 0x7f54772d95d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "pred = svd.predict(df_val)\n",
        "mae = mean_absolute_error(df_val['rating'], pred)\n",
        "rmse = mean_squared_error(df_val['rating'], pred)\n",
        "print(mae, rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiC9BIpO5ho9",
        "outputId": "f5858ade-f390-45fd-e8c5-bb8f2ac95d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6849643586112794 0.7812732900551826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svd.metrics_['MAE']"
      ],
      "metadata": {
        "id": "UP-Q4UCB5tfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tuning"
      ],
      "metadata": {
        "id": "TJGv36lPleLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "orPQxeDBp49F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = [0.01, 0.001, 0.0001]\n",
        "K = [10, 20, 30, 40]\n",
        "lambda_p = [0.001, 0.003, 0.005, 0.007]"
      ],
      "metadata": {
        "id": "Xk51NguApJI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for l in lr:\n",
        "  for k in K:\n",
        "    for reg in lambda_p:\n",
        "      svd = SVD(lr=l, reg=reg, n_epochs=150, n_factors=k, shuffle=False, min_rating=1, max_rating=5)\n",
        "      svd.fit(X=df, X_val=df_val)\n",
        "      pred = svd.predict(df_val)\n",
        "      mae = mean_absolute_error(df_val['rating'], pred)\n",
        "      rmse = mean_squared_error(df_val['rating'], pred)\n",
        "      print(l, reg, k, mae, rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV35BDxFpKt1",
        "outputId": "4f3691d1-2b77-47ba-c250-3b7944c0296f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.001 10 0.09719960166416113 0.13261182625774198\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.003 10 0.10767117759650323 0.13988939769515854\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.005 10 0.10967723182158011 0.1303204301494839\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.007 10 0.11064583948633475 0.1301593477415536\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.001 20 0.09798938947423688 0.13184486064261067\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.003 20 0.10363431410303994 0.12993024781231652\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.005 20 0.10734481969939637 0.12798941910254413\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.007 20 0.11155931763618608 0.12992452029650242\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.001 30 0.09697601338999773 0.13094773247361705\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.003 30 0.1007035420788153 0.12651654315376215\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 1 sec\n",
            "0.01 0.005 30 0.10642332271250796 0.12785480799995602\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 1 sec\n",
            "0.01 0.007 30 0.1098633946227739 0.12753348832372086\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.001 40 0.09803096878967112 0.13437430460613312\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.003 40 0.10092646726547151 0.12636950684769446\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.005 40 0.10846846707666034 0.12993045600787537\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.01 0.007 40 0.1098929732460645 0.12744804748046162\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.001 10 0.1646414741728979 0.1673920951136652\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.003 10 0.18854143491544723 0.1746729630373713\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.005 10 0.18703643227533318 0.17061230510737938\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.007 10 0.21996327083836775 0.1855811477194491\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.001 20 0.14526787204300423 0.16647884863265514\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.003 20 0.15568902555969763 0.16366701844625836\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.005 20 0.18914449229111105 0.17624301802745213\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.007 20 0.19974336630672143 0.18137299310981045\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.001 30 0.139454051642488 0.16338358160479813\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.003 30 0.15767458662455083 0.16485254795815113\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.005 30 0.1717720142371548 0.16490088593801877\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.007 30 0.19223820176135029 0.17048331791350813\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.001 40 0.13760319597485784 0.16088433644939723\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.003 40 0.14831323789269932 0.15515413942319664\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.005 40 0.16807709256531483 0.16166949082494037\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.001 0.007 40 0.1948383337700542 0.17654924512905518\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.001 10 0.984078447836772 1.7074582146560167\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.003 10 0.9829081595629794 1.7009582464349962\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.005 10 0.9800760984157232 1.6974920876094775\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.007 10 0.9835322325028911 1.708087367845466\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.001 20 0.9813344274556381 1.7004830957743848\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.003 20 0.9805270138534479 1.6956508019765248\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.005 20 0.9812025760975209 1.7007620903021636\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.007 20 0.9805499128871729 1.6995529190275738\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.001 30 0.9737158729593777 1.6785485226414576\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.003 30 0.9765661059496614 1.691191727803496\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.005 30 0.9791564976314177 1.694633184689454\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.007 30 0.9729118235754619 1.6782287583588054\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.001 40 0.9696182555203414 1.6669384061631147\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.003 40 0.9655911047190299 1.65050896008522\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.005 40 0.9728706440651468 1.675117282351042\n",
            "Preprocessing data...\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "\n",
            "Training took 0 sec\n",
            "0.0001 0.007 40 0.9691740847021327 1.663834726147871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD"
      ],
      "metadata": {
        "id": "N-vXld-yBEGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install implicit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7v-qjnsBmVD",
        "outputId": "e267e841-4099-4360-ffa5-0bb9465ed372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting implicit\n",
            "  Downloading implicit-0.5.2-cp37-cp37m-manylinux2014_x86_64.whl (18.5 MB)\n",
            "\u001b[K     || 18.5 MB 472 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from implicit) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from implicit) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from implicit) (4.64.0)\n",
            "Installing collected packages: implicit\n",
            "Successfully installed implicit-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rating matrix wrt user u\n",
        "ru_src = src.pivot_table(index='userId',columns='itemId',values='rating')    # U\n",
        "ru_src = ru_src.fillna(0)\n",
        "ru_m_src = ru_src > 0\n",
        "ru_m_src = ru_m_src.replace(True, 1)\n",
        "ru_m_src = ru_m_src.replace(False, 0)\n",
        "ru_src = np.array(ru_src)\n",
        "ru_m_src = np.array(ru_m_src)   # U"
      ],
      "metadata": {
        "id": "NaznVnL0B02D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix factorization(MF) via singular value decomposition(SVD) ad bm25_weight\n",
        "\n",
        "import scipy.sparse.linalg\n",
        "from implicit.nearest_neighbours import bm25_weight\n",
        "\n",
        "k = 10\n",
        "\n",
        "us, x2, vs = scipy.sparse.linalg.svds(bm25_weight(ru_src), k)"
      ],
      "metadata": {
        "id": "hRB2Fm8gBC4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWFsA6P3BtHn",
        "outputId": "47c9fccd-63d1-481f-b723-69a730cb93da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1098, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.9\n",
        "df_copy = tr.copy()\n",
        "train_set = df_copy.sample(frac=train_size).reset_index()\n",
        "user_features_train = np.array(train_set[['open', 'cons', 'extra', 'agree', 'neuro']].reset_index().fillna(0))\n",
        "test_set = df_copy.drop(train_set.index).reset_index()\n",
        "user_features_test = np.array(test_set[['open', 'cons', 'extra', 'agree', 'neuro']].reset_index().fillna(0))"
      ],
      "metadata": {
        "id": "u7NhG7DgCHKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rating matrix wrt user u\n",
        "ru_src = test_set.pivot_table(index='userId',columns='itemId',values='rating')    # U\n",
        "ru_src = ru_src.fillna(0)\n",
        "ru_m_src = ru_src > 0\n",
        "ru_m_src = ru_m_src.replace(True, 1)\n",
        "ru_m_src = ru_m_src.replace(False, 0)\n",
        "ru_src = np.array(ru_src)\n",
        "ru_m_src = np.array(ru_m_src)   # U"
      ],
      "metadata": {
        "id": "GuPfuv4YCn7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = test_set.pivot_table(index='userId',columns='itemId',values='rating').fillna(0).reset_index()\n",
        "cols = arr.columns\n",
        "cols = cols[1:len(arr.T)]"
      ],
      "metadata": {
        "id": "nFFERGLbCrqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = arr.userId"
      ],
      "metadata": {
        "id": "V7e5iLHbDhJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_group = src.groupby(by='userId').mean().reset_index().reset_index()"
      ],
      "metadata": {
        "id": "MnDLHBzWJJZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = []\n",
        "for i in arr.userId:\n",
        "  for j in range(len(src_group)):\n",
        "    if i == src_group.userId[j]:\n",
        "      ids.append(src_group['index'][j])"
      ],
      "metadata": {
        "id": "fCtRAg3FIk08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for i in range(len(rows)):\n",
        "  row = []\n",
        "  for j in range(len(cols)):\n",
        "    x = np.array(vs.T[0]).reshape(k,1)\n",
        "    y = np.array(us[ids[0]]).reshape(1,k)\n",
        "    p = y @ x\n",
        "    row.append(p)\n",
        "  pred.append(row)"
      ],
      "metadata": {
        "id": "ijvNVyjOD58T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.array(pred).reshape(len(pred), len(pred[0]))"
      ],
      "metadata": {
        "id": "Jjoj_KRoLyCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mae = mean_absolute_error(ru_src, pred)\n",
        "rmse = mean_squared_error(ru_src, pred)\n",
        "print(mae, rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5FLUUdgJ0jp",
        "outputId": "eb947423-9de9-4ca2-f90c-810db56ebce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03455038104534231 0.14983418538841162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ru_src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXfb_cvHL2pu",
        "outputId": "1272c1ad-2af8-44a2-ee65-956367e3f8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 3.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4aeUGkQ-MFK3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}